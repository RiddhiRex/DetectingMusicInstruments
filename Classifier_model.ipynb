{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Admin\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import neighbors\n",
    "from sklearn import decomposition\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_traindata():\n",
    "    music_data = []\n",
    "    #reading all files recursively\n",
    "    files = glob.glob('Datasets\\TrainingData\\*\\*.wav')\n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    for filename in files:\n",
    "        #Preprocess the music file to get features from it\n",
    "        music, sr = librosa.load(filename)\n",
    "        mfccs = librosa.feature.mfcc(y=music, sr=sr)\n",
    "        mean_mfccs = np.mean(mfccs, axis = 1)\n",
    "        feature = mean_mfccs.reshape(20)\n",
    "        if '[cel]' in filename[25:38]:\n",
    "            instrument_code = 1\n",
    "        elif '[flu]' in filename[25:38]:\n",
    "            instrument_code = 2\n",
    "        elif '[gac]' in filename[25:38]:\n",
    "            instrument_code = 3\n",
    "        elif '[gel]' in filename[25:38]:\n",
    "            instrument_code = 4\n",
    "        elif '[org]' in filename[25:38]:\n",
    "            instrument_code = 5\n",
    "        elif '[pia]' in filename[25:38]:\n",
    "            instrument_code = 6\n",
    "        elif '[sax]' in filename[25:38]:\n",
    "            instrument_code = 7\n",
    "        elif '[tru]' in filename[25:38]:\n",
    "            instrument_code = 8\n",
    "        elif '[vio]' in filename[25:38]:\n",
    "            instrument_code = 9\n",
    "        elif '[cla]' in filename[25:38]:\n",
    "            instrument_code = 10\n",
    "        elif '[voi]' in filename[25:38]:\n",
    "            instrument_code = 11\n",
    "        else:\n",
    "            instrument_code = 0\n",
    "            print('Unknown instrument found in the file', filename)\n",
    "        #Append the filename, feature and instrument list of each file into a list\n",
    "        #filelist.append(filename)\n",
    "        #featurelist.append(feature)\n",
    "        #inst_code.append(instrument)\n",
    "        #Copy the list into a dataframe\n",
    "        #df=pd.DataFrame()    \n",
    "        #df['filename']= filelist\n",
    "        #df['feature']= featurelist\n",
    "        #df['instrumentcode']= inst_code\n",
    "        file_data = [filename, feature, instrument_code]\n",
    "        music_data.append(file_data)\n",
    "\n",
    "    return music_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_testdata():\n",
    "    music_data = []\n",
    "\n",
    "    #reading all files recursively\n",
    "    files = glob.glob('Datasets\\TestingData-Part1\\Part1\\*.wav')\n",
    "    np.random.shuffle(files)\n",
    "\n",
    "    for filename in files:\n",
    "        #Preprocess the music file to get features from it\n",
    "        music, sr = librosa.load(filename)\n",
    "        mfccs = librosa.feature.mfcc(y=music, sr=sr)\n",
    "        mean_mfccs = np.mean(mfccs, axis = 1)\n",
    "        feature = mean_mfccs.reshape(20)\n",
    "        # Open the corresponding text file containing list of instruments.\n",
    "        instrument_file = os.path.splitext(filename)[0]+'.txt'\n",
    "        #CHECK IF THE FILE IS TAKEN FROM THE RIGHT PATH\n",
    "        f = open(instrument_file, 'r')\n",
    "        instrument = []\n",
    "        for word in f:\n",
    "            if 'cel' in word:\n",
    "                instrument_code = 1\n",
    "            elif 'cla' in word:\n",
    "                instrument_code = 2\n",
    "            elif 'flu' in word:\n",
    "                instrument_code = 3\n",
    "            elif 'gac' in word:\n",
    "                instrument_code = 4\n",
    "            elif 'gel' in word:\n",
    "                instrument_code = 5\n",
    "            elif 'org' in word:\n",
    "                instrument_code = 6\n",
    "            elif 'pia' in word:\n",
    "                instrument_code = 7\n",
    "            elif 'sax' in word:\n",
    "                instrument_code = 8\n",
    "            elif 'tru' in word:\n",
    "                instrument_code = 9\n",
    "            elif 'vio' in word:\n",
    "                instrument_code = 10\n",
    "            elif 'voi' in word:\n",
    "                instrument_code = 11\n",
    "            else:\n",
    "                instrument_code = 0\n",
    "            instrument.append(instrument_code)\n",
    "        #Append the filename, feature and instrument list of each file into a list\n",
    "        #filelist.append(filename)\n",
    "        #featurelist.append(feature)\n",
    "        #inst_code.append(instrument)\n",
    "        #Copy the list into a dataframe\n",
    "        #df=pd.DataFrame()    \n",
    "        #df['filename']= filelist\n",
    "        #df['feature']= featurelist\n",
    "        #df['instrumentcode']= inst_code\n",
    "        file_data = [filename, feature, instrument]\n",
    "        music_data.append(file_data)\n",
    "\n",
    "        #return df\n",
    "    return music_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_data(data):\n",
    "    filename = np.array(map(lambda n: n[0], data))\n",
    "    feature = np.array(map(lambda n: n[1], data))\n",
    "    instrument = np.array(map(lambda n: n[2], data))\n",
    "    return filename, feature, instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    #Copy the parameters into a dataframe\n",
    "    #df = pd.DataFrame()\n",
    "    #df['feature'] = features\n",
    "    #df['instrumentcode'] = instrument_code\n",
    "    #Copying the paramters into an array\n",
    "    #features = np.array(features)\n",
    "    #instrument_code = np.array(instrument_code)\n",
    "    filename, features, instrument_code = unpack_data(data)\n",
    "    \n",
    "    X = preprocessing.Imputer().fit_transform(features)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(instrument_code)\n",
    "    estimators = [(\"scale\", preprocessing.StandardScaler()),\n",
    "                  ('svm', svm.SVC(decision_function_shape='ovo'))]\n",
    "    \n",
    "    clf = Pipeline(estimators)\n",
    "    params = dict(svm__kernel=['rbf'], svm__C=[0.1],\n",
    "                  svm__degree=[1, 3], svm__gamma=[0.01])\n",
    "    gs = GridSearchCV(clf, param_grid=params, cv=10, verbose=2)\n",
    "    gs.fit(X, y)\n",
    "    prediction = gs.predict(X)\n",
    "    \n",
    "    Evaluate_accuracy(prediction, y)\n",
    "    #PCA\n",
    "    #pca = decomposition.PCA(n_components=10)\n",
    "    #features = pca.fit_transform(features)\n",
    "    \n",
    "    #SVM\n",
    "    #svc = svm.LinearSVC()\n",
    "    #svc.fit(features, instrument_code)\n",
    "    \n",
    "    #KNN\n",
    "    #knn = neighbors.KNeighborsClassifier(n_neighbors=12)\n",
    "    #knn.fit(features, instrument_code)\n",
    "\n",
    "    #return svc\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    filename, features, instrument_code = unpack_data(data)\n",
    "    \n",
    "    #PCA\n",
    "    #features = pca.transform(features)\n",
    "    \n",
    "    #SVM\n",
    "    prediction = model.predict(features)\n",
    "    \n",
    "    #mlb = MultiLabelBinarizer()\n",
    "    #instrument_code = mlb.fit_transform(instrument_code)/mlb.transform(instrument_code)\n",
    "    \n",
    "    #KNN\n",
    "    #prediction = model.predict(features)\n",
    "\n",
    "    #Evaluate the performance\n",
    "    Evaluate_accuracy(prediction, instrument_code)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluate_accuracy(pred, true_value):\n",
    "    #Evaluate the accuracy of the model\n",
    "\n",
    "    print(\"Accuracy score is\", accuracy_score(true_value.astype(int), pred.astype(int))*100)\n",
    "    print(\"Mean squared error\", mean_squared_error(true_value, pred))\n",
    "    rmse = np.sqrt(mean_squared_error(true_value, pred))\n",
    "    print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "    print(\"Mean absolute error:\", mean_absolute_error(true_value,pred))\n",
    "    print(\"Classification Report: \",classification_report(true_value, pred))\n",
    "    print('confusion matrix:', confusion_matrix(true_value, pred))\n",
    "    print \"Micro stats:\"\n",
    "    print precision_recall_fscore_support(true_value, pred, average='micro')\n",
    "    print \"Macro stats:\"\n",
    "    print precision_recall_fscore_support(true_value, pred, average='macro')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    joblib.dump(model, 'gsclsclassifier.model')\n",
    "    #joblib.dump(pca, 'pcaclassifier.model')\n",
    "    #joblib.dump(model, 'svmclassifier.model')\n",
    "    #joblib.dump(knn, 'knnclassifier.model')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "    #model = joblib.load('newclassifier.model')\n",
    "    #pca = joblib.load('pcaclassifier.model')\n",
    "    svc = joblib.load('svmclassifier.model')\n",
    "    #knn = joblib.load('knnclassifier.model')\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_data = preprocess_traindata()\n",
    "\n",
    "    model= train(train_data)\n",
    "    saveModel(model)\n",
    "\n",
    "    #model = loadModel()\n",
    "    #test_data = preprocess_testdata()\n",
    "    #test_data = preprocess_traindata()\n",
    "    #predict(model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   9.1s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.8s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.8s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.8s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=1, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.9s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.8s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.7s\n",
      "[CV] svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 .....\n",
      "[CV]  svm__degree=3, svm__C=0.1, svm__kernel=rbf, svm__gamma=0.01 -   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy score is', 38.031319910514547)\n",
      "('Mean squared error', 12.879940343027592)\n",
      "Root Mean Squared Error: 3.58886337759\n",
      "('Mean absolute error:', 2.410439970171514)\n",
      "('Classification Report: ', '             precision    recall  f1-score   support\\n\\n          0       0.78      0.08      0.14       388\\n          1       0.56      0.07      0.12       451\\n          2       0.40      0.52      0.45       637\\n          3       0.35      0.44      0.39       760\\n          4       0.37      0.56      0.45       682\\n          5       0.41      0.56      0.47       721\\n          6       0.30      0.23      0.26       626\\n          7       0.51      0.27      0.35       577\\n          8       0.45      0.28      0.35       580\\n          9       0.51      0.19      0.28       505\\n         10       0.33      0.61      0.42       778\\n\\navg / total       0.43      0.38      0.35      6705\\n')\n",
      "('confusion matrix:', array([[ 31,   2,  89,  52,  19,  58,  36,   1,  63,   4,  33],\n",
      "       [  2,  31,  53,  21,  98,  86,  21,  11,  27,  27,  74],\n",
      "       [  0,   0, 333,  44,  66,  60,  19,   4,   4,   0, 107],\n",
      "       [  1,   1,  37, 337,  81,  56,  25,   6,  15,   0, 201],\n",
      "       [  1,   0,  30,  96, 380,  13,   5,  15,   4,   2, 136],\n",
      "       [  1,   1,  42,  43, 107, 402,  43,  11,   5,   4,  62],\n",
      "       [  0,   3,  51,  71,  50,  87, 146,  63,  13,  15, 127],\n",
      "       [  2,   5,  16,  55,  62,  70,  52, 156,  26,  27, 106],\n",
      "       [  1,   5,  61,  80,  37,  53,  64,  10, 165,  11,  93],\n",
      "       [  1,   7,  72,  47,  22,  96,  67,  22,  37,  96,  38],\n",
      "       [  0,   0,  50, 114, 102,   8,  13,   6,   9,   3, 473]]))\n",
      "Micro stats:\n",
      "(0.38031319910514544, 0.38031319910514544, 0.38031319910514544, None)\n",
      "Macro stats:\n",
      "(0.45071493277784475, 0.34688204167794512, 0.33565231678868362, None)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On testing with training data itself:\n",
    "When using KNN:\n",
    "('Accuracy score is', 62.4750499001996)\n",
    "('Mean squared error', 7.3732534930139719)\n",
    "Root Mean Squared Error: 2.71537354576\n",
    "('Mean absolute error:', 1.4131736526946108)\n",
    "When using SVM:\n",
    "('Number of filessssssssssssss trained', 1001)\n",
    "('Accuracy score is', 14.685314685314685)\n",
    "('Mean squared error', 31.002997002997002)\n",
    "Root Mean Squared Error: 5.56803349514\n",
    "('Mean absolute error:', 4.615384615384615)\n",
    "\n",
    "when using this code:\n",
    "    X = preprocessing.Imputer().fit_transform(features)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(instrument_code)\n",
    "    estimators = [(\"scale\", preprocessing.StandardScaler()),\n",
    "                  ('svm', svm.SVC(decision_function_shape='ovo'))]\n",
    "    \n",
    "    clf = Pipeline(estimators)\n",
    "    params = dict(svm__kernel=['rbf'], svm__C=[0.1],\n",
    "                  svm__degree=[1, 3], svm__gamma=[0.01])\n",
    "    gs = GridSearchCV(clf, param_grid=params, cv=10, verbose=2)\n",
    "    gs.fit(X, y)\n",
    "    prediction = gs.predict(X)\n",
    "    \n",
    "('Accuracy score is', 38.031319910514547)\n",
    "('Mean squared error', 12.879940343027592)\n",
    "Root Mean Squared Error: 3.58886337759\n",
    "('Mean absolute error:', 2.410439970171514)\n",
    "('Classification Report: ', '             precision    recall  f1-score   support\\n\\n          0       0.78      0.08      0.14       388\\n          1       0.56      0.07      0.12       451\\n          2       0.40      0.52      0.45       637\\n          3       0.35      0.44      0.39       760\\n          4       0.37      0.56      0.45       682\\n          5       0.41      0.56      0.47       721\\n          6       0.30      0.23      0.26       626\\n          7       0.51      0.27      0.35       577\\n          8       0.45      0.28      0.35       580\\n          9       0.51      0.19      0.28       505\\n         10       0.33      0.61      0.42       778\\n\\navg / total       0.43      0.38      0.35      6705\\n')\n",
    "('confusion matrix:', array([[ 31,   2,  89,  52,  19,  58,  36,   1,  63,   4,  33],\n",
    "       [  2,  31,  53,  21,  98,  86,  21,  11,  27,  27,  74],\n",
    "       [  0,   0, 333,  44,  66,  60,  19,   4,   4,   0, 107],\n",
    "       [  1,   1,  37, 337,  81,  56,  25,   6,  15,   0, 201],\n",
    "       [  1,   0,  30,  96, 380,  13,   5,  15,   4,   2, 136],\n",
    "       [  1,   1,  42,  43, 107, 402,  43,  11,   5,   4,  62],\n",
    "       [  0,   3,  51,  71,  50,  87, 146,  63,  13,  15, 127],\n",
    "       [  2,   5,  16,  55,  62,  70,  52, 156,  26,  27, 106],\n",
    "       [  1,   5,  61,  80,  37,  53,  64,  10, 165,  11,  93],\n",
    "       [  1,   7,  72,  47,  22,  96,  67,  22,  37,  96,  38],\n",
    "       [  0,   0,  50, 114, 102,   8,  13,   6,   9,   3, 473]]))\n",
    "Micro stats:\n",
    "(0.38031319910514544, 0.38031319910514544, 0.38031319910514544, None)\n",
    "Macro stats:\n",
    "(0.45071493277784475, 0.34688204167794512, 0.33565231678868362, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
