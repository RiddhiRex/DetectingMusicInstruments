{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from os import sys, path\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IRMAS = 1\n",
    "PHILHARMONIA = 2\n",
    "MIS = 3\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_preprocessing(dataset):\n",
    "    if(dataset == IRMAS):\n",
    "        # import wav files to build features\n",
    "        files = glob.glob('Datasets\\*.csv')\n",
    "        dfs = []\n",
    "        for filename in files:\n",
    "            dfs.append(pd.read_csv(filename))     \n",
    "        # Concatenate all dataFrames into a single DataFrame\n",
    "        data = pd.concat(dfs, ignore_index=True)\n",
    "        data.fillna(0, inplace=True)\n",
    "        \n",
    "    if(dataset == PHILHARMONIA):\n",
    "        files = glob.glob('Datasets\\philharmoni\\*.csv')\n",
    "        dfs = []\n",
    "        for filename in files:\n",
    "            dfs.append(pd.read_csv(filename))\n",
    "        # Concatenate all dataFrames into a single DataFrame\n",
    "        data = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "    if(dataset == MIS):\n",
    "        files = glob.glob('Datasets\\MIS_Dataset\\*.csv')\n",
    "        dfs = []\n",
    "        for filename in files:\n",
    "            dfs.append(pd.read_csv(filename))     \n",
    "        # Concatenate all dataFrames into a single DataFrame\n",
    "        data = pd.concat(dfs, ignore_index=True)\n",
    "        data.fillna(0, inplace=True)\n",
    "    print \"Done reading the music files\"\n",
    "    \n",
    "    features = data.drop(['class'], axis=1).values\n",
    "    features = preprocessing.Imputer().fit_transform(features)\n",
    "    inst_code = data['class']\n",
    "\n",
    "    steps = [(\"scale\", preprocessing.StandardScaler()),\n",
    "              ('anova_filter', SelectKBest(mutual_info_classif, k=100)),\n",
    "              ('svm', svm.SVC(decision_function_shape='ovo'))]\n",
    "\n",
    "    model = Pipeline(steps)\n",
    "    return model, features, inst_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, dataset):\n",
    "    if dataset ==IRMAS:\n",
    "        joblib.dump(model, 'irmas.model')\n",
    "    if dataset == PHILHARMONIA:\n",
    "        joblib.dump(model, 'Philharmonia.model')\n",
    "    if dataset ==MIS:\n",
    "        joblib.dump(model, 'mis.model')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel(dataset):\n",
    "    if dataset ==IRMAS:\n",
    "        model = joblib.load('irmas.model')\n",
    "    if dataset == PHILHARMONIA:\n",
    "        model = joblib.load('Philharmonia.model')\n",
    "    if dataset ==MIS:\n",
    "        model = joblib.load('mis.model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(clf, music_features, instrument_code, dataset):\n",
    "    print(\"Fitting the data\")\n",
    "    clf.fit(music_features, instrument_code)\n",
    "    print(\"Save the model\")\n",
    "    saveModel(clf, dataset)\n",
    "    print(\"Testing the model\")\n",
    "    detected_instrument = clf.predict(music_features)    \n",
    "    print(\"Quantify the performance\")\n",
    "    Evaluate_accuracy(detected_instrument, instrument_code)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluate_accuracy(detected_instrument, true_value):\n",
    "    print(\"Accuracy score is \", accuracy_score(true_value, detected_instrument)*100)\n",
    "    rmse = np.sqrt(mean_squared_error(true_value, detected_instrument))\n",
    "    print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "    \n",
    "    print(\"Classification Report: \")\n",
    "    cr = classification_report(true_value, detected_instrument)\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = ['Unknown', 'Piano','Organ', 'Guitar','Acoustic guitar','Mandolin','Electric guitar','Violin','Cello','Trumpet','Sax','Clarinet','Flute','Banjo','Voice', 'Avg']\n",
    "    rep = np.array(precision_recall_fscore_support(true_value, detected_instrument)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "    plt.title('Classification Report :')\n",
    "    rep =rep.astype('float') / rep.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(rep, annot=True, xticklabels=xticks, yticklabels=yticks, cmap=\"BuGn\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Confusion matrix :')\n",
    "    cm=confusion_matrix(true_value,detected_instrument)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    inst = ['Unknown instrument', 'Piano','Organ', 'Guitar','Acoustic guitar','Mandolin','Electric guitar','Violin','Cello','Trumpet','Sax','Clarinet','Flute','Banjo','Voice']\n",
    "    sns.heatmap(cm, annot=True, xticklabels=inst, yticklabels=inst, fmt=\".2f\", linewidths=.5, cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted instrument code')\n",
    "    plt.ylabel('True value')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing on IRMAS dataset\n",
      "Done reading the music files\n",
      "Fitting the data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Training and testing on IRMAS dataset\")\n",
    "    classifier, X, y = feature_preprocessing(IRMAS)\n",
    "    train_test(classifier, X, y, IRMAS)\n",
    "    print(\"Training and testing on PHILHARMONIA dataset\")\n",
    "    classifier, X, y = feature_preprocessing(PHILHARMONIA)\n",
    "    train_test(classifier, X, y, PHILHARMONIA)\n",
    "    print(\"Training and testing on IOWA MIS dataset\")\n",
    "    classifier, X, y = feature_preprocessing(MIS)\n",
    "    train_test(classifier, X, y, MIS)\n",
    "    \n",
    "    #model1 = loadModel(IRMAS)\n",
    "    #test(model1, X, y)\n",
    "    \n",
    "    #model2 = loadModel(RWC)\n",
    "    #test(model2, X, y)\n",
    "    \n",
    "    #model3 = loadModel(PHILHARMONIA)\n",
    "    #test(model3, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "Training and testing on IRMAS dataset(and rwc)\n",
    "Done reading the music files\n",
    "1\n",
    "(12051L, 372L)\n",
    "(12051L,)\n",
    "Fitting the data\n",
    "Save the model\n",
    "Testing the model\n",
    "Quantify the performance\n",
    "('Accuracy score is ', 68.558625840179246)\n",
    "Root Mean Squared Error: 3.34109129573\n",
    "('Mean absolute error:', 1.5432744170608248)\n",
    "Micro stats:\n",
    "(0.68558625840179244, 0.68558625840179244, 0.68558625840179244, None)\n",
    "Macro stats:\n",
    "(0.71898022698999386, 0.70117690730693982, 0.68939606489333938, None)\n",
    "('Classification Report: ', '             precision    recall  f1-score   support\\n\\n          0       0.39      0.73      0.50       722\\n          1       0.47      0.72      0.57       682\\n          2       0.99      0.95      0.97       106\\n          3       0.58      0.58      0.58       637\\n          4       1.00      0.44      0.61        80\\n          5       0.58      0.62      0.60       760\\n          6       0.80      0.79      0.80      1835\\n          7       0.79      0.71      0.75      1277\\n          8       0.76      0.63      0.69      1062\\n          9       0.78      0.51      0.62      1358\\n         10       0.74      0.72      0.73      1351\\n         11       0.95      0.70      0.80      1329\\n         12       0.62      0.99      0.76        74\\n         13       0.62      0.73      0.67       778\\n\\navg / total       0.72      0.69      0.69     12051\\n')\n",
    "\n",
    "Training and testing on RWC dataset\n",
    "Done reading the music files\n",
    "2\n",
    "(3544L, 368L)\n",
    "(3544L,)\n",
    "Fitting the data\n",
    "Save the model\n",
    "Testing the model\n",
    "Quantify the performance\n",
    "('Accuracy score is ', 83.267494356659142)\n",
    "Root Mean Squared Error: 4.93881868695\n",
    "('Mean absolute error:', 1.2751128668171559)\n",
    "Micro stats:\n",
    "(0.83267494356659144, 0.83267494356659144, 0.83267494356659144, None)\n",
    "Macro stats:\n",
    "(0.87961986518969237, 0.79530164377962864, 0.81644049595788171, None)\n",
    "('Classification Report: ', '             precision    recall  f1-score   support\\n\\n          0       0.89      0.92      0.90        36\\n          1       1.00      0.83      0.91        30\\n          2       0.91      1.00      0.95        10\\n          3       0.97      0.86      0.91        42\\n          4       0.84      0.88      0.86        24\\n          5       1.00      0.60      0.75        20\\n          6       0.91      0.96      0.93        45\\n          7       1.00      0.55      0.71        22\\n          8       0.92      1.00      0.96        36\\n          9       0.87      1.00      0.93        27\\n         10       1.00      0.92      0.96        36\\n         11       1.00      0.59      0.74        27\\n         12       1.00      0.98      0.99        43\\n         13       0.91      0.92      0.91        63\\n         14       0.70      0.82      0.76        57\\n         15       0.66      0.88      0.75        57\\n         16       0.87      0.82      0.85        57\\n         17       0.92      0.85      0.88        65\\n         18       0.94      0.95      0.95        66\\n         19       0.91      1.00      0.95       252\\n         20       0.82      0.89      0.86        90\\n         21       0.94      0.98      0.96       105\\n         22       1.00      0.89      0.94        18\\n         23       0.56      0.69      0.62        54\\n         24       0.87      0.70      0.78        37\\n         25       1.00      0.58      0.73        38\\n         26       0.77      0.54      0.63        37\\n         27       0.96      0.67      0.79        36\\n         28       1.00      0.78      0.88        36\\n         29       1.00      0.75      0.86        36\\n         30       0.97      0.83      0.90        36\\n         31       1.00      1.00      1.00        38\\n         32       1.00      0.77      0.87        39\\n         33       0.97      0.83      0.90        36\\n         34       1.00      0.79      0.89        39\\n         35       0.00      0.00      0.00        18\\n         36       0.91      0.77      0.83        39\\n         37       0.82      0.87      0.85        63\\n         38       1.00      1.00      1.00        12\\n         39       1.00      0.35      0.52        37\\n         40       1.00      0.07      0.12        76\\n         41       0.75      0.65      0.70       188\\n         42       0.69      0.90      0.78       262\\n         43       0.76      0.89      0.82       184\\n         44       0.94      0.80      0.86       162\\n         45       0.72      0.95      0.82       162\\n         46       0.72      0.91      0.80       162\\n         47       0.80      0.91      0.85       162\\n         48       0.95      0.75      0.84       162\\n         49       0.84      0.94      0.89       165\\n\\navg / total       0.85      0.83      0.82      3544\\n')\n",
    "C:\\Users\\Admin\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "\n",
    "Training and testing on PHILHARMONICA dataset\n",
    "Done reading the music files\n",
    "3\n",
    "(5345L, 372L)\n",
    "(5345L,)\n",
    "Fitting the data\n",
    "Save the model\n",
    "Testing the model\n",
    "Quantify the performance\n",
    "('Accuracy score is ', 97.343311506080454)\n",
    "Root Mean Squared Error: 0.600436386363\n",
    "('Mean absolute error:', 0.070907390084190836)\n",
    "Micro stats:\n",
    "(0.97343311506080454, 0.97343311506080454, 0.97343311506080454, None)\n",
    "Macro stats:\n",
    "(0.94799850484804005, 0.93801257128445081, 0.93641155563669853, None)\n",
    "('Classification Report: ', '             precision    recall  f1-score   support\\n\\n          0       0.97      0.97      0.97       106\\n          1       0.98      0.64      0.77        80\\n          2       0.98      0.98      0.98      1255\\n          3       0.97      0.97      0.97       889\\n          4       0.99      0.95      0.97       485\\n          5       0.98      0.97      0.97       732\\n          6       0.97      0.99      0.98       846\\n          7       1.00      1.00      1.00       878\\n          8       0.70      0.97      0.81        74\\n\\navg / total       0.98      0.97      0.97      5345\\n')\n",
    "\n",
    "\n",
    "\n",
    "MIS dataset:\n",
    "('Accuracy score is ', 99.387254901960787)\n",
    "Root Mean Squared Error: 0.598199914121\n",
    "('Mean absolute error:', 0.046568627450980393)\n",
    "Micro stats:\n",
    "(0.99387254901960786, 0.99387254901960786, 0.99387254901960786, None)\n",
    "Macro stats:\n",
    "(0.99363381716322885, 0.98621107476069303, 0.98958542764970203, None)\n",
    "\n",
    "\n",
    "\n",
    "irmas dataset+rwc+mis( model2:\n",
    "('Accuracy score is ', 71.461879225926793)\n",
    "Root Mean Squared Error: 10.2347248121\n",
    "('Mean absolute error:', 4.2853034895469033)\n",
    "Micro stats:\n",
    "(0.71461879225926794, 0.71461879225926794, 0.71461879225926794, None)\n",
    "Macro stats:\n",
    "(0.75093259483969033, 0.73832350327427787, 0.72985875750350049, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
